\documentclass[10pt]{article}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{fancyhdr,url,hyperref}
\usepackage{graphicx,xspace}
\usepackage{subfigure}
\usepackage{tikz}
\usetikzlibrary{arrows,decorations.pathmorphing,backgrounds,positioning,fit,through}

\oddsidemargin 0in  %0.5in
\topmargin     0in
\leftmargin    0in
\rightmargin   0in
\textheight    9in
\textwidth     6in %6in
%\headheight    0in
%\headsep       0in
%\footskip      0.5in

\newtheorem{thm}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{obs}{Observation}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}
\newtheorem{question}{Question}
\newtheorem{answer}{Answer}
\newtheorem{problem}{Problem}
\newtheorem{solution}{Solution}
\newtheorem{conjecture}{Conjecture}

\pagestyle{fancy}

\lhead{\textsc{Prof. Baumer}}
\chead{\textsc{MTH 220: Lecture notes}}
\lfoot{}
\cfoot{}
%\cfoot{\thepage}
\rfoot{}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.0pt}

\newcommand{\ans}{\vspace{0.25in}}
\newcommand{\R}{{\sf R}\xspace}
\newcommand{\cmd}[1]{\texttt{#1}}
\newcommand{\Ex}{\mathbb{E}}

\rhead{\textsc{November 18, 2016}}

\begin{document}

\paragraph{Agenda}
\begin{enumerate}
  \itemsep0em
  \item Difference of paired samples
  \item Difference of two means
\end{enumerate}

\paragraph{Warmup: Gifted Children's Parents}

Since in this data set, the IQ of both parents is recorded for all children, the IQ data is naturally paired. 

<<message=FALSE, size='footnotesize', warning=FALSE>>=
require(mosaic)
require(openintro)
favstats(~motheriq, data = gifted)
favstats(~fatheriq, data = gifted)
@


We can define a new variable, \texttt{diff}, to be the difference between the mother's IQ and the father's for each gifted child. 
  
<<size='footnotesize', tidy=FALSE>>=
gifted <- gifted %>%
  mutate(diff = motheriq - fatheriq)
favstats(~diff, data = gifted)
@

Recall the conditions for using a $t$-based sampling distribution for a single mean:
\begin{enumerate}
  \item The samples come from independent observations
  \item The distribution of the original variable is approximately normal, or the sample size is large
\end{enumerate}

We return to our original questions:

\begin{enumerate}
  \itemsep1in
  \item Find a 90\% confidence interval for the mean IQ of the mothers. Do the same for the fathers. Do they overlap? 
  \item Test the hypothesis that the mothers of gifted children have higher IQs, on average, than the fathers. Write out all of the steps. What do you conclude?

  
  \begin{enumerate}
    \itemsep0.5in
    \item State the null and alternative hypotheses
    \item Check that \texttt{diff} meets the conditions listed above
    \item Compute the standard error of the mean ($SE_{\texttt{diff}}$) and the degrees of freedom
    \item Compute the test statistic ($T$)
    \item Compute the p-value and draw a conclusion [Use the table at the back of the book, or the \cmd{pt()} function in \R.]
    \item Write a sentence that provides an interpretation of your result
  \end{enumerate}
  \vspace{0.5in}
\end{enumerate}


\paragraph{Difference of two means}

Often the data are \emph{not} naturally paired. In particular, we are often interested in comparing mean from two groups of unequal sizes. For example, the 11 children whose fathers had higher IQs than mothers had a lower average score on the skills test than the 25 children whose mothers had higher IQs than the fathers. 

<<size='footnotesize'>>=
favstats(score ~ (diff > 0), data = gifted)
@

Now the samples are \emph{not} naturally paired. How do we know if the observed difference in means between these two groups is meaningful? Let $X$ be the random variable that gives the analytical skills test score for a gifted child whose father has a higher IQ than her mother, and let $Y$ be the random variable that gives the test score for a gifted child whose mother has a higher IQ. Then we need to understand the sampling distribution of the test statistic $D = \bar{X}- \bar{Y}$.

Just as we did with proportions, the standard error of the difference is a combination of the standard errors of the variables. 
$$
  SE_D  = \sqrt{(SE_X)^2 + (SE_Y)^2}
$$

If both $X$ and $Y$ meet the conditions for a $t$-based sampling distribution, then $D$ will meet those conditions as well. We typically use $\min(n_1-1, n_2-1)$ for the degrees of freedom.

The hypothesis test for a difference of two means constructed in this manner is called the \emph{two-sample $t$-test}, and it is a commonly applied statistical technique. 

\begin{enumerate}
  \itemsep1in
  \item Use the information above to conduct a two-sample $t$-test for a difference in mean test score between gifted children whose fathers have higher IQs vs. those whose mothers have higher IQs.
\end{enumerate}


% 
% \newpage
% 
% \paragraph{Solution to Warmup}
% 
% We need to make three intervals:
% 
% <<message=FALSE>>=
% require(mosaic)
% require(openintro)
% n <- nrow(gifted)
% # mothers
% mean_m <- mean(~motheriq, data = gifted)
% se_m <- sd(~motheriq, data = gifted) / sqrt(n)
% mean_m + qt(c(0.05, 0.95), df = (n - 1)) * se_m
% # fathers
% mean_f <- mean(~fatheriq, data = gifted)
% se_f <- sd(~fatheriq, data = gifted) / sqrt(n)
% mean_f + qt(c(0.05, 0.95), df = (n - 1)) * se_f
% # pairs
% gifted <- mutate(gifted, diff = motheriq - fatheriq)
% x_bar <- mean(~diff, data = gifted)
% se <- sd(~diff, data = gifted) / sqrt(n)
% 2 * pt(x_bar/se, df = (n-1), lower.tail = FALSE)
% @
% 
% 
% Recall that by definition, the standard error $SE_D$ is the standard deviation of the sampling distribution of the test statistic, $D$. Thus, \emph{since $D$ is not a mean},
% 
% $$
%   SE_{D} = \sigma_{D} = \sqrt{Var(D)} = \sqrt{Var(\bar{X} - \bar{Y})} 
% $$
% If $X$ and $Y$ are independent, then we have:
% $$
%   \sqrt{Var(\bar{X} - \bar{Y})}  = \sqrt{Var(\bar{X}) + Var(\bar{Y})} = \sqrt{\sigma_{\bar{X}}^2 + \sigma_{\bar{Y}}^2} = \sqrt{(SE_{\bar{X}})^2 + (SE_{\bar{Y}})^2}
% $$
% We need to verify that both $X$ and $Y$ are distributed approximately normally. If they are, then $SE_{\bar{X}} = \sigma_X / \sqrt{n}$ and $SE_{\bar{Y}} = \sigma_Y / \sqrt{n}$. Thus, 
% $$
%   SE_{D} = \sqrt{ \left( \frac{\sigma_X}{\sqrt{n_X}} \right)^2 + \left( \frac{\sigma_Y}{\sqrt{n_Y}} \right)^2} = \sqrt{ \frac{\sigma_X^2}{n_X} + \frac{\sigma_Y^2}{n_Y}}
% $$
% 
% 
% \paragraph{Solution to two-sample t-test}
% 
% <<>>=
% fv <- favstats(score ~ (diff > 0), data = gifted) %>%
%   mutate(se = sd / sqrt(n))
% fv %>%
%   summarize(obs = diff(mean), 
%             se = sqrt(sum(se^2)), 
%             df = min(n - 1)) %>%
%   mutate(p_value = 2 * pt(obs/se, df = df, lower.tail = FALSE))
% @
% 
% To match the output from \cmd{t.test()}, use the more complicated estimate of d.f.
% 
% <<>>=
% fv %>%
%   mutate(se_i = se^4 / (n - 1)) %>%
%   summarize(obs = diff(mean), 
%             num = (sum(se^2))^2, 
%             denom = (sum(se_i / (n - 1)))) %>%
%   mutate(df = num / denom, 
%          p_value = 2 * pt(obs/se, df = df, lower.tail = FALSE))
% t.test(score ~ (diff > 0), data = gifted)
% @



\end{document}
